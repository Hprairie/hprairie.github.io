{
    "title": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting",
    "authors": "Author, A. A., Author, B. B., & Author, C. C.",
    "year": "2024",
    "venue": "Conference on Machine Learning (ICML)",
    "description": "Fine-tuning a pre-trained model on a downstream task often degrades its original capabilities, a phenomenon known as 'catastrophic forgetting'. This work proposes a sample weighting scheme for fine-tuning that helps preserve pre-trained model capabilities while maintaining performance on the target task. We demonstrate the effectiveness of our method on both language and vision tasks.",
    "links": [
        {
            "name": "GitHub",
            "url": "https://github.com/yourusername/upweighting-easy-samples"
        },
        {
            "name": "arXiv",
            "url": "https://arxiv.org/abs/2024.xxxxx"
        },
        {
            "name": "Paper",
            "url": "#"
        }
    ]
}
